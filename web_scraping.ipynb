{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pdf file object\n",
    "\n",
    "pdfFileObj = open('FADH resume.pdf', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pdf reader object\n",
    "\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of pages in the pdf file\n",
    "len(pdfReader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a page\n",
    "page = pdfReader.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the text on the required page\n",
    "print(page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING DATA FROM WORD FILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING A WORD FILE OBJECT\n",
    "\n",
    "document = open(\"Report of 16th Feb-Fadhlullah.docx\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read =docx.Document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(read.paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list to hold the document's text\n",
    "document_text =[]\n",
    "#loop through each paragraph in the document\n",
    "\n",
    "for paragraph in read.paragraphs:\n",
    "    document_text.append(paragraph.text)\n",
    "document_text\n",
    "\n",
    "#join the list into a single string with newline characters\n",
    "\n",
    "full_text= '\\n'.join(document_text)\n",
    "print(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.paragraphs[22].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE LIBRARIES\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  credentials\n",
    "consumer_key=\n",
    "consumer_secret=\n",
    "access_token=\n",
    "access_token_secret="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling API\n",
    "auth= tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query to search for finance and stock-related tweets from BBC News, excluding retweets\n",
    "query= 'finance OR stock OR market OR investment from:BBCNews -filter:retweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the API to search for tweets containing the query\n",
    "tweets =api.search_tweets(q=query, count=10, lang='en', tweet_mode='extended') # adjust for more results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "#define your keys from the developer portal\n",
    "bearer_token=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client =tweepy.client(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query to search for finance and stock_related tweets from BBC News, excluding retweets\n",
    "\n",
    "query= 'finance OR stock OR market OR investment from:BBCNews -is:retweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the API to search tweets containing the query\n",
    "response =client.search_recent_tweets(query=query, max_results=10, tweet_fields=['created_at','text','author_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING NTSCRAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nitter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper =Nitter(log_level=1, skip_instance_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.get_tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =scraper.get_tweets(\"elonmusk\", mode= \"user\", number= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={\n",
    "    'date':[],\n",
    "    'link':[],\n",
    "    'text':[],\n",
    "    'user':[],\n",
    "    'likes':[],\n",
    "    'quotes':[],\n",
    "    'retweets':[],\n",
    "    'comments':[]\n",
    "}\n",
    "\n",
    "for tweet in tweets['tweets']:\n",
    "    data['date'].append(tweet['date'])\n",
    "    data['link'].append(tweet['link'])\n",
    "    data['text'].append(tweet['text'])\n",
    "    data['user'].append(tweet['user']['name'])\n",
    "    data['likes'].append(tweet['stats']['likes'])\n",
    "    data['quotes'].append(tweet['stats']['quotes'])\n",
    "    data['retweets'].append(tweet['stats']['retweets'])\n",
    "    data['comments'].append(tweet['stats']['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the scraped tweets into a csv file\n",
    "\n",
    "data={\n",
    "    'date':[],\n",
    "    'link':[],\n",
    "    \"text\":[],\n",
    "    \"user\":[],\n",
    "    \"likes\":[],\n",
    "    \"quotes\":[],\n",
    "    \"retweets\":[],\n",
    "    \"comments\":[]\n",
    "    }\n",
    "\n",
    "for tweet in tweets['tweets']:\n",
    "    data['date'].append(tweet['date'])\n",
    "    data['link'].append(tweet['link'])\n",
    "    data['text'].append(tweet['text'])\n",
    "    data['user'].append(tweet['user']['name'])\n",
    "    data['likes'].append(tweet['stats']['likes'])\n",
    "    data['quotes'].append(tweet['stats']['quotes'])\n",
    "    data['retweets'].append(tweet['stats']['retweets'])\n",
    "    data['comments'].append(tweet['stats']['comments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
